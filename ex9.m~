clear all;
clc;
close all;
toPlot = 0;
averageTestError = 0;
averageTrainError = 0;
nLoops = 200;
nTableTrainPoints=[10,100];
resultsMatrix=zeros(2);
X=boston(:,1:13);
Y=boston(:,14);
nLoop=1
MSEresults=zeros(nLoop,15);

for i=1:nLoop
    
    %generate training set and test set
    [n1,d1]=size(X);
    randomIndexes=randPerm(n1);
    sizeTraining=2*n1/3;
    trainX=X(randomIndexes(1:sizeTraining),:);
    testX=Y(randomIndexes(1:sizeTraining),:);
    trainY=X(randomIndexes(sizeTraining+1:n1,:);
    testY=Y(randomIndexes(sizeTraining+1:n1,:);
    
    % implementation of naive regression 
    
    naiveOnesTrain=ones(sizeTraining,1);
    naiveOnesTest=ones(n1-sizeTraining,1);
    MSEresults(i,1)=linearRegression(naiveOnesTrain,naiveOnesTest,trainY,testY);
    
    % implementation of linear regression withonefeature
    
    for i =1:13
        featureTrain=train
    
    averageTestError = averageTestError / nLoops
    averageTrainError = averageTrainError / nLoops

    resultsMatrix(i,1)=averageTrainError;
    resultsMatrix(i,2)=averageTestError;

end
resultsMatrix
