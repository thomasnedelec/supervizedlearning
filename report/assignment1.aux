\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Exercise 1: Least Square Regression: effect of the training set size}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  (a) training set of 10 points (b) training set of 100 points (c) the entire data set\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:lsr}{{1}{1}{(a) training set of 10 points (b) training set of 100 points (c) the entire data set\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average mean square error for both training and test sets, on both 10 and 100 element-size training set with running 200 times the algorithm.\relax }}{1}{figure.caption.2}}
\newlabel{fig:resultMatrix1}{{2}{1}{Average mean square error for both training and test sets, on both 10 and 100 element-size training set with running 200 times the algorithm.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Exercise 2: Least Square Regression: effect of dimensionality}{2}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average mean square error for 10-dimensional data for both training and test sets, on both 10 and 100 element-size training set with running 200 times the algorithm.\relax }}{2}{figure.caption.3}}
\newlabel{fig:resultMatrix2}{{3}{2}{Average mean square error for 10-dimensional data for both training and test sets, on both 10 and 100 element-size training set with running 200 times the algorithm.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Exercise 3: Ridge regression}{2}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Effect of the regularisation parameter}{3}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Evaluation of the training error and test error in function of gamma for 100 training samples.\relax }}{3}{figure.caption.4}}
\newlabel{fig:ex4_100}{{4}{3}{Evaluation of the training error and test error in function of gamma for 100 training samples.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Evaluation of the training error and test error in function of gamma for 10 training samples.\relax }}{4}{figure.caption.5}}
\newlabel{fig:ex4_10}{{5}{4}{Evaluation of the training error and test error in function of gamma for 10 training samples.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Tuning the regularization parameter using a validation set}{4}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average MSE in function of gamma .\relax }}{5}{figure.caption.6}}
\newlabel{fig:ex5}{{6}{5}{Average MSE in function of gamma .\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Tuning the regularization parameter using cross validation}{5}{section.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Evaluation of the mean square error in function of gamma for different number of training examples.\relax }}{6}{figure.caption.7}}
\newlabel{fig:ex6}{{7}{6}{Evaluation of the mean square error in function of gamma for different number of training examples.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Comparison of $\gamma $ tuning methods}{6}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Load the data}{7}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Baseline versus full linear regression.}{7}{section.9}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Kernel Ridge Regression}{7}{section.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Cross-validation error as a function of $\gamma $ and $\sigma $.\relax }}{8}{figure.caption.8}}
\newlabel{fig:ex910}{{8}{8}{Cross-validation error as a function of $\gamma $ and $\sigma $.\relax }{figure.caption.8}{}}
\newlabel{fig:res}{{10}{8}{Kernel Ridge Regression}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Part 2}{9}{section.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Simulating {1-Nearest Neighbor classifier} with Linear Classifier}{9}{subsection.11.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Using a perceptron to learn a linear classifier with a bias}{9}{subsection.11.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Perceptron\relax }}{9}{algorithm.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Kernel modification}{9}{subsection.11.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4}Sparse learning}{10}{subsection.11.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Evolution of sample complexity according to dimension for perceptron\relax }}{10}{figure.caption.9}}
\newlabel{fig:lsr}{{9}{10}{Evolution of sample complexity according to dimension for perceptron\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  Evolution of sample complexity according to dimension for least square algorithm\relax }}{11}{figure.caption.10}}
\newlabel{fig:lsr}{{10}{11}{Evolution of sample complexity according to dimension for least square algorithm\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  Evolution of sample complexity according to dimension for winnow algorithm\relax }}{11}{figure.caption.11}}
\newlabel{fig:lsr}{{11}{11}{Evolution of sample complexity according to dimension for winnow algorithm\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  Evolution of sample complexity according to dimension for perceptron\relax }}{11}{figure.caption.12}}
\newlabel{fig:lsr}{{12}{11}{Evolution of sample complexity according to dimension for perceptron\relax }{figure.caption.12}{}}
